<div align="center">

# âš–ï¸ Kanoonu AI ğŸ›ï¸

### *Your AI-Powered Legal Companion for Indian Law*

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://reactjs.org/)
[![Flask](https://img.shields.io/badge/Flask-2.3+-000000?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Latest-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)

**A comprehensive legal assistance platform powered by AI, providing instant legal advice, case law search, and more - all trained on Indian law.**

[Features](#-features) â€¢ [Installation](#-installation--setup) â€¢ [Usage](#-usage-guide)
</div>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¤– AI-Powered Features
- **AI Legal Chatbot** - Instant legal advice powered by Gemma-2-2B Indian Law model
- **Case Law Search** - AI-powered case analysis and insights
- **Smart Voice Assistant** - Speech-to-text and text-to-speech
- **GPU Acceleration** - Optimized for RTX 3050+ GPUs

</td>
<td width="50%">

### ğŸ“š Legal Resources
- **Document Templates** - Ready-to-use legal document templates
- **Video Tutorials** - Step-by-step legal procedure guides
- **Lawyer Directory** - Connect with qualified legal professionals
- **Admin Dashboard** - Complete content management system

</td>
</tr>
<tr>
<td colspan="2">

### ğŸŒ User Experience
- **Multilingual Support** - Full support for English & Kannada
- **Responsive Design** - Works seamlessly on desktop and mobile
- **Real-time Updates** - Instant responses and hot reload during development

</td>
</tr>
</table>

---

## ğŸ› ï¸ Tech Stack

<div align="center">

| Category | Technologies |
|----------|-------------|
| **Backend** | ![Python](https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=white) ![Flask](https://img.shields.io/badge/-Flask-000000?logo=flask&logoColor=white) ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?logo=pytorch&logoColor=white) |
| **Frontend** | ![React](https://img.shields.io/badge/-React-61DAFB?logo=react&logoColor=black) ![Vite](https://img.shields.io/badge/-Vite-646CFF?logo=vite&logoColor=white) ![TailwindCSS](https://img.shields.io/badge/-Tailwind-06B6D4?logo=tailwindcss&logoColor=white) |
| **AI/ML** | ![HuggingFace](https://img.shields.io/badge/-HuggingFace-FFD21E?logo=huggingface&logoColor=black) Gemma-2-2B-Indian-Law Model |
| **Tools** | ![Git](https://img.shields.io/badge/-Git-F05032?logo=git&logoColor=white) ![npm](https://img.shields.io/badge/-npm-CB3837?logo=npm&logoColor=white) |

</div>

### Backend Stack
- **Framework**: Python 3.10+, Flask
- **AI Model**: Gemma-2-2B-Indian-Law (Hugging Face Transformers)
- **Libraries**: PyTorch, Accelerate, Flask-CORS, BeautifulSoup4
- **Device Support**: CPU / CUDA GPU (NVIDIA)

### Frontend Stack
- **Framework**: React 18 with Vite
- **Styling**: Tailwind CSS, Framer Motion
- **Icons**: Lucide React
- **Routing**: React Router DOM v6
- **HTTP Client**: Axios

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:

| Requirement | Version | Required | Notes |
|------------|---------|----------|-------|
| **Python** | 3.10.11+ | âœ… Yes | Core backend runtime |
| **Node.js** | 16+ | âœ… Yes | Frontend development |
| **npm** | 8+ | âœ… Yes | Comes with Node.js |
| **Git** | Latest | âœ… Yes | Version control |
| **RAM** | 4GB+ | âœ… Yes | For AI model loading |
| **CUDA GPU** | RTX 3050+ | âš ï¸ Optional | Faster AI inference |

> **ğŸ’¡ Tip**: Use `python --version` and `node --version` to check your installed versions.


## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/TEJAS-G0WDA/KANOONU-AI.git
cd kanoonu-ai
```

---

### 2ï¸âƒ£ Backend Setup

<details>
<summary><b>ğŸ“¦ Step 1: Create Virtual Environment</b></summary>

**Windows (PowerShell):**
```powershell
python -m venv venv
.\venv\Scripts\activate
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

</details>

<details>
<summary><b>ğŸ“¥ Step 2: Install Python Dependencies</b></summary>

```bash
pip install -r requirements.txt
```

</details>

<details>
<summary><b>âš¡ Step 3: (Optional) Install CUDA PyTorch for GPU Acceleration</b></summary>

If you have an NVIDIA GPU with CUDA support:

```bash
# For CUDA 12.1 (RTX 30/40 series)
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# For CUDA 11.8 (Older GPUs)
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Verify GPU Setup:**
```python
import torch
print(torch.cuda.is_available())  # Should return True
```

</details>

<details>
<summary><b>ğŸ¤– Step 4: Download AI Model (IMPORTANT!)</b></summary>

> **âš ï¸ CRITICAL STEP**: The AI model is **NOT included** in the repository due to its large size (~5GB).

#### Option A: Automatic Download (Recommended)
The model will **automatically download** from Hugging Face on first run:

```bash
python app.py
```

The model will be saved to `./model/gemma2-indian-law/` for future use.

#### Option B: Manual Download

1. **Install Hugging Face CLI:**
   ```bash
   pip install huggingface-hub
   ```

2. **Login to Hugging Face** (optional, for gated models):
   ```bash
   huggingface-cli login
   ```

3. **Download the model:**
   ```bash
   huggingface-cli download Ananya8154/Gemma-2-2B-Indian-Law --local-dir ./model/gemma2-indian-law
   ```

4. **Verify download:**
   ```bash
   # Check if config.json exists
   ls ./model/gemma2-indian-law/config.json
   ```

#### Expected Model Structure:
```
model/
â””â”€â”€ gemma2-indian-law/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.safetensors
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ ... (other model files)
```

> **ğŸ“ Note**: First download takes 10-15 minutes depending on your internet speed. The model is approximately **5GB** in size.

</details>

---

### 3ï¸âƒ£ Frontend Setup

<details>
<summary><b>ğŸ“‚ Step 1: Navigate to Frontend Directory</b></summary>

```bash
cd frontend
```

</details>

<details>
<summary><b>ğŸ“¦ Step 2: Install Node Dependencies</b></summary>

```bash
npm install
```

This installs:
- âš›ï¸ React & React DOM
- âš¡ Vite (build tool)
- ğŸ¨ Tailwind CSS
- ğŸ§­ React Router DOM
- ğŸ“¡ Axios
- ğŸ¯ Lucide React (icons)
- ğŸ¬ Framer Motion (animations)

</details>

---

## â–¶ï¸ Running the Application

> **âš¡ Quick Start**: Run both backend and frontend in separate terminals.

### ğŸ”· Terminal 1: Start Backend Server

```powershell
# Navigate to project root
cd kanoonu-ai

# Activate virtual environment
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Start Flask backend
python app.py
```

**âœ… Expected Output:**
```
============================================================
ğŸš€ Starting Kanoonu AI Server...
============================================================
âœ… Tokenizer loaded successfully
â³ Loading model checkpoint shards...
ğŸ’¡ Tip: Server will start immediately. Model loading continues in background.
ğŸŒ Server starting on http://127.0.0.1:5000
============================================================
 * Running on http://127.0.0.1:5000
```

**What Happens:**
- âœ… Server starts **immediately** on `http://localhost:5000`
- ğŸ“¦ AI model loads in background (5-10 min on CPU, 1-2 min on GPU)
- ğŸš€ API endpoints available while model loads
- â³ AI features work once model loading completes

---

### ğŸ”¶ Terminal 2: Start Frontend Development Server

```powershell
# Open a new terminal
cd kanoonu-ai/frontend

# Start Vite dev server
npm run dev
```

**âœ… Expected Output:**
```
  VITE v7.2.0  ready in 234 ms

  âœ  Local:   http://localhost:5173/
  âœ  Network: use --host to expose
  âœ  press h + enter to show help
```

---

### ğŸŒ Access the Application

<div align="center">

| Service | URL | Description |
|---------|-----|-------------|
| **Frontend** | http://localhost:5173 | Main application |
| **Backend API** | http://localhost:5000 | Flask REST API |
| **Health Check** | http://localhost:5000/health | Server status & model info |

</div>

> **ğŸ’¡ Pro Tip**: Bookmark the health check endpoint to monitor AI model loading status!

## ğŸ” Health Check & Monitoring

To check if the backend and AI model are ready:

```bash
curl http://localhost:5000/health
```

**Sample Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_loading": false,
  "device": "cuda",
  "model_error": null,
  "timestamp": "2026-02-03T10:30:00Z"
}
```

**Field Descriptions:**
- `model_loaded`: **true** = AI ready | **false** = Still loading
- `model_loading`: Currently loading the model?
- `device`: **cuda** = GPU | **cpu** = CPU
- `model_error`: Error message if model failed to load

---

## ğŸ“ Project Structure

```
kanoonu-ai/
â”œâ”€â”€ ğŸ“„ app.py                          # Flask backend server (main entry point)
â”œâ”€â”€ ğŸ“„ requirements.txt                # Python dependencies
â”œâ”€â”€ ğŸ“– README.md                       # This file
â”œâ”€â”€ ğŸ“– BACKEND_START_GUIDE.md          # Backend troubleshooting guide
â”œâ”€â”€ ğŸ“– FRONTEND_START_GUIDE.md         # Frontend setup & troubleshooting
â”œâ”€â”€ ğŸ“– SETUP_INSTRUCTIONS.md           # Detailed installation guide
â”‚
â”œâ”€â”€ ğŸ“‚ features/                       # Backend features & utilities
â”‚   â””â”€â”€ case_scraper.py               # Case law web scraping module
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/                       # âš›ï¸ React frontend application
â”‚   â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ components/            # Reusable React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx           # Navigation bar
â”‚   â”‚   â”‚   â””â”€â”€ Footer.jsx           # Footer component
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ pages/                 # Page components (routes)
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx             # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Chatbot.jsx          # AI chatbot interface
â”‚   â”‚   â”‚   â”œâ”€â”€ AILawyer.jsx         # AI lawyer consultation
â”‚   â”‚   â”‚   â”œâ”€â”€ CaseLawSearch.jsx    # Legal case search
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentTemplates.jsx # Document templates
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoTutorials.jsx   # Video tutorial library
â”‚   â”‚   â”‚   â”œâ”€â”€ Lawyers.jsx          # Lawyer directory
â”‚   â”‚   â”‚   â”œâ”€â”€ Admin.jsx            # Admin dashboard
â”‚   â”‚   â”‚   â””â”€â”€ AdminLogin.jsx       # Admin authentication
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ contexts/
â”‚   â”‚   â”‚   â””â”€â”€ LanguageContext.jsx  # i18n language switching
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useSpeechAssistant.js # Voice interaction hook
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”‚   â”‚   â””â”€â”€ legalGlossary.js     # Legal terms dictionary
â”‚   â”‚   â”œâ”€â”€ api.js                   # API client configuration
â”‚   â”‚   â”œâ”€â”€ App.jsx                  # Main app component
â”‚   â”‚   â”œâ”€â”€ main.jsx                 # React entry point
â”‚   â”‚   â””â”€â”€ index.css                # Global styles
â”‚   â”œâ”€â”€ ğŸ“‚ public/                    # Static assets (images, icons)
â”‚   â”œâ”€â”€ package.json                  # Node.js dependencies
â”‚   â”œâ”€â”€ vite.config.js               # Vite bundler config
â”‚   â””â”€â”€ tailwind.config.js           # Tailwind CSS config
â”‚
â”œâ”€â”€ ğŸ“‚ model/                          # ğŸ¤– AI model directory
â”‚   â””â”€â”€ gemma2-indian-law/            # âš ï¸ Download separately (see setup)
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ model.safetensors
â”‚       â”œâ”€â”€ tokenizer.json
â”‚       â””â”€â”€ ... (other model files)
â”‚
â”œâ”€â”€ ğŸ“‚ templates/                      # Legacy HTML templates (optional)
â”œâ”€â”€ ğŸ“‚ static/                         # Legacy static files (optional)
â””â”€â”€ ğŸ“‚ uploads/                        # User file uploads directory
```

> **ğŸ”´ Important**: The `model/gemma2-indian-law/` directory is **NOT included** in the repository. Follow [Step 4 of Backend Setup](#2ï¸âƒ£-backend-setup) to download the AI model.

---

## ğŸ’¡ Usage Guide

### ğŸ‘¤ For Users:

| Feature | Description | How to Access |
|---------|-------------|---------------|
| ğŸ¤– **Chat with AI** | Ask legal questions in plain English/Kannada | Navigate to "AI Lawyer" or "Chatbot" |
| ğŸ” **Search Cases** | Find relevant legal precedents | Use "Case Law Search" page |
| ğŸ“„ **Access Templates** | Download legal document templates | Visit "Document Templates" |
| ğŸ“¹ **Watch Tutorials** | Learn legal procedures step-by-step | Go to "Video Tutorials" |
| ğŸ‘¨â€âš–ï¸ **Find Lawyers** | Connect with legal professionals | Browse "Lawyer Directory" |

### ğŸ” For Admins:

1. **Login** - Access admin panel at `http://localhost:5173/admin-login`
2. **Default Credentials**:
   - Username: `admin`
   - Password: `1234`
   - âš ï¸ **Change these in production!**
3. **Admin Features**:
   - ğŸ‘¨â€âš–ï¸ Manage lawyer profiles
   - ğŸ“„ Upload/update document templates
   - ğŸ“¹ Add/update video tutorials
   - ğŸ“Š View system analytics

---

## ğŸ› Troubleshooting

<details>
<summary><b>ğŸ”´ Backend Issues</b></summary>

### âŒ Port 5000 Already in Use

**Check what's using the port:**
```powershell
netstat -ano | findstr :5000
```

**Kill the process (Windows):**
```powershell
taskkill /PID <PID> /F
```

**Kill the process (Linux/Mac):**
```bash
kill -9 <PID>
```

---

### â³ Model Loading Hangs or Takes Too Long

**Possible Causes:**
- âŒ Insufficient RAM (needs 4GB+ free)
- âŒ Model files corrupted
- âŒ Slow internet (if downloading)

**Solutions:**
1. **Check available RAM:**
   - Close unnecessary applications
   - Open Task Manager (Ctrl+Shift+Esc) to monitor RAM

2. **Clear and re-download model:**
   ```bash
   # Delete model directory
   Remove-Item -Recurse model/gemma2-indian-law
   
   # Restart server (will auto-download)
   python app.py
   ```

3. **Check model files:**
   ```bash
   # Verify config.json exists
   ls model/gemma2-indian-law/config.json
   ```

---

### ğŸ“¦ Dependency Installation Errors

```bash
# Upgrade pip first
python -m pip install --upgrade pip

# Reinstall requirements
pip install --upgrade -r requirements.txt
```

---

### ğŸš« CUDA/GPU Not Detected

**Verify CUDA installation:**
```python
import torch
print(torch.cuda.is_available())  # Should return True
print(torch.cuda.get_device_name(0))  # Your GPU name
```

**If False, reinstall PyTorch with CUDA:**
```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

</details>

<details>
<summary><b>ğŸ”µ Frontend Issues</b></summary>

### âŒ Port 5173 Already in Use

**Edit** `vite.config.js` to use a different port:
```javascript
export default {
  server: {
    port: 3001 // Change port number
  }
}
```

Or kill the process:
```powershell
# Windows
netstat -ano | findstr :5173
taskkill /PID <PID> /F
```

---

### ğŸ“¦ npm Install Fails

```bash
# Clear npm cache
npm cache clean --force

# Delete node_modules and reinstall
Remove-Item -Recurse -Force node_modules
Remove-Item package-lock.json
npm install
```

---

### ğŸŒ API Connection Errors / CORS Issues

**Symptoms:**
- Console shows CORS errors
- API calls fail with 404/500 errors

**Solutions:**
1. **Ensure backend is running** on port 5000
2. **Check API endpoint** in `frontend/src/api.js`:
   ```javascript
   const API_URL = 'http://localhost:5000';
   ```
3. **Verify CORS config** in `app.py`:
   ```python
   CORS(app, origins=['http://localhost:5173'], supports_credentials=True)
   ```

---

### ğŸ–¥ï¸ Blank White Page

1. **Open Browser Console** (F12)
2. **Check for errors** in Console tab
3. **Check Network tab** for failed requests
4. **Clear browser cache** and hard reload (Ctrl+Shift+R)

</details>

<details>
<summary><b>ğŸŸ¡ General Issues</b></summary>

### ğŸ“š Where are the logs?

**Backend logs:** Check terminal where `python app.py` is running

**Frontend logs:** Open Browser DevTools (F12) â†’ Console tab

---

### ğŸ”„ How to restart everything?

1. **Stop both servers** (Ctrl+C in both terminals)
2. **Restart backend:**
   ```bash
   python app.py
   ```
3. **Restart frontend:**
   ```bash
   cd frontend
   npm run dev
   ```

---

### ğŸ†˜ Still Having Issues?

1. Check [BACKEND_START_GUIDE.md](BACKEND_START_GUIDE.md) for detailed backend troubleshooting
2. Check [FRONTEND_START_GUIDE.md](FRONTEND_START_GUIDE.md) for frontend-specific issues
3. Check [SETUP_INSTRUCTIONS.md](SETUP_INSTRUCTIONS.md) for step-by-step setup
4. Open an issue on GitHub with:
   - Error messages
   - System info (OS, Python version, Node version)
   - Steps to reproduce

</details>

---



## System Requirements & Performance

### Minimum Requirements

| Component | Specification |
|-----------|--------------|
| **CPU** | Intel i5 / AMD Ryzen 5 (4 cores) |
| **RAM** | 8GB (4GB free for model) |
| **Storage** | 10GB free space |
| **OS** | Windows 10+, Ubuntu 20.04+, macOS 11+ |
| **Internet** | Required for initial model download |

### Recommended Requirements (For Best Performance)

| Component | Specification |
|-----------|--------------|
| **CPU** | Intel i7 / AMD Ryzen 7 (8 cores) |
| **RAM** | 16GB+ |
| **GPU** | NVIDIA RTX 3050+ (4GB VRAM) |
| **Storage** | 20GB+ SSD |
| **Internet** | 10+ Mbps for model download |

### Performance Benchmarks

| Hardware | Model Load Time | Inference Speed (per query) |
|----------|----------------|---------------------------|
| **CPU Only** | 5-10 minutes | 10-15 seconds |
| **RTX 3050** | 1-2 minutes | 2-3 seconds |
| **RTX 4060+** | 30-60 seconds | 1-2 seconds |

> **ğŸ’¡ Tip**: GPU acceleration reduces inference time by **5-10x** compared to CPU.

---


## ğŸ“ Support & Documentation

| Resource | Description |
|----------|-------------|
| ğŸ“– [README.md](README.md) | Main documentation (this file) |
| ğŸ”§ [BACKEND_START_GUIDE.md](BACKEND_START_GUIDE.md) | Backend troubleshooting & setup |
| âš›ï¸ [FRONTEND_START_GUIDE.md](FRONTEND_START_GUIDE.md) | Frontend setup & development |
| ğŸ“‹ [SETUP_INSTRUCTIONS.md](SETUP_INSTRUCTIONS.md) | Detailed installation guide |

---

<div align="center">

### â­ If you find this project helpful, please consider giving it a star!

**Made with â¤ï¸ for the Legal Community**

[![GitHub stars](https://img.shields.io/github/stars/your-username/kanoonu-ai?style=social)](https://github.com/your-username/kanoonu-ai/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/your-username/kanoonu-ai?style=social)](https://github.com/your-username/kanoonu-ai/network/members)

</div>
